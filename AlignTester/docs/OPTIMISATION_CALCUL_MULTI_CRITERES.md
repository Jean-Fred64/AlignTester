# Optimisation du Calcul Multi-Crit√®res

## üìã Vue d'ensemble

Ce document propose des optimisations pour am√©liorer la pr√©cision et la fiabilit√© du calcul multi-crit√®res utilis√© dans `alignment_parser.py` pour √©valuer l'alignement d'un lecteur de disquettes.

---

## üîç Analyse du Calcul Actuel

### Formule Actuelle

```python
adjusted_percentage = (
    sector_score * 0.40 +      # 40% - Score bas√© sur les secteurs d√©tect√©s
    quality_score * 0.30 +      # 30% - Moyenne de coh√©rence et stabilit√©
    azimuth_final * 0.15 +      # 15% - Score d'azimut
    asymmetry_final * 0.15      # 15% - Score d'asym√©trie
)
```

### Probl√®mes Identifi√©s

1. **Valeurs par d√©faut probl√©matiques** :
   - Si `azimuth_score` ou `asymmetry_score` sont `None`, on utilise `100.0`
   - Cela peut fausser le r√©sultat vers le haut si les m√©triques ne sont pas disponibles
   - Un score de 100% par d√©faut n'est pas r√©aliste

2. **Pond√©ration fixe** :
   - Les poids sont fixes (40%, 30%, 15%, 15%)
   - Pas d'adaptation selon la disponibilit√© des donn√©es
   - Pas d'adaptation selon la qualit√© des m√©triques

3. **Pas de normalisation** :
   - Les scores peuvent avoir des √©chelles diff√©rentes
   - Pas de v√©rification de coh√©rence entre les m√©triques

4. **Pas de seuils de confiance** :
   - On ne tient pas compte de la fiabilit√© de chaque m√©trique
   - Une m√©trique calcul√©e avec peu de donn√©es devrait avoir moins de poids

5. **Pas de gestion des cas limites** :
   - Si une m√©trique est tr√®s mauvaise (< 50%), elle devrait avoir plus d'impact n√©gatif
   - Les m√©triques critiques (secteurs) devraient avoir un poids minimum garanti

---

## üí° Propositions d'Optimisation

### Proposition 1 : Pond√©ration Adaptative selon la Disponibilit√© des Donn√©es

**Principe** : Ajuster les poids selon quelles m√©triques sont disponibles.

**Avantages** :
- √âvite de p√©naliser si une m√©trique n'est pas disponible (pas assez de lectures)
- R√©partit le poids des m√©triques manquantes sur les m√©triques disponibles
- Plus r√©aliste que d'utiliser 100% par d√©faut

**Impl√©mentation** :

```python
def calculate_adaptive_weights(
    has_sector_score: bool,
    has_quality_score: bool,
    has_azimuth: bool,
    has_asymmetry: bool
) -> Dict[str, float]:
    """
    Calcule les poids adaptatifs selon la disponibilit√© des m√©triques
    """
    # Poids de base (id√©al)
    base_weights = {
        'sector': 0.40,
        'quality': 0.30,
        'azimuth': 0.15,
        'asymmetry': 0.15
    }
    
    # Identifier les m√©triques disponibles
    available = {
        'sector': has_sector_score,
        'quality': has_quality_score,
        'azimuth': has_azimuth,
        'asymmetry': has_asymmetry
    }
    
    # Calculer le poids total disponible
    total_available_weight = sum(
        base_weights[k] for k, v in available.items() if v
    )
    
    if total_available_weight == 0:
        # Aucune m√©trique disponible, utiliser poids par d√©faut
        return base_weights
    
    # Redistribuer les poids proportionnellement
    weights = {}
    for key in base_weights:
        if available[key]:
            # Redistribuer proportionnellement
            weights[key] = base_weights[key] / total_available_weight
        else:
            weights[key] = 0.0
    
    return weights
```

### Proposition 2 : Seuils de Confiance et Pond√©ration par Fiabilit√©

**Principe** : R√©duire le poids des m√©triques peu fiables (calcul√©es avec peu de donn√©es).

**Avantages** :
- Les m√©triques calcul√©es avec beaucoup de lectures ont plus de poids
- Les m√©triques calcul√©es avec peu de lectures ont moins de poids
- Plus r√©aliste et fiable

**Impl√©mentation** :

```python
def calculate_confidence_weights(
    num_readings: int,
    consistency: Optional[float],
    stability: Optional[float],
    azimuth_cv: Optional[float],
    asymmetry_percent: Optional[float]
) -> Dict[str, float]:
    """
    Calcule les poids en fonction de la confiance de chaque m√©trique
    """
    base_weights = {
        'sector': 0.40,
        'quality': 0.30,
        'azimuth': 0.15,
        'asymmetry': 0.15
    }
    
    # Facteurs de confiance (0.0 √† 1.0)
    confidence_factors = {
        'sector': 1.0,  # Toujours disponible si on a des lectures
        'quality': min(1.0, num_readings / 3.0),  # N√©cessite au moins 3 lectures
        'azimuth': min(1.0, num_readings / 3.0),  # N√©cessite au moins 3 lectures
        'asymmetry': min(1.0, num_readings / 3.0)  # N√©cessite au moins 3 lectures
    }
    
    # Ajuster les facteurs selon la disponibilit√©
    if consistency is None and stability is None:
        confidence_factors['quality'] = 0.0
    if azimuth_cv is None:
        confidence_factors['azimuth'] = 0.0
    if asymmetry_percent is None:
        confidence_factors['asymmetry'] = 0.0
    
    # Calculer les poids ajust√©s
    adjusted_weights = {
        k: base_weights[k] * confidence_factors[k]
        for k in base_weights
    }
    
    # Normaliser pour que la somme = 1.0
    total = sum(adjusted_weights.values())
    if total > 0:
        adjusted_weights = {k: v / total for k, v in adjusted_weights.items()}
    else:
        # Fallback : utiliser seulement le score de secteurs
        adjusted_weights = {'sector': 1.0, 'quality': 0.0, 'azimuth': 0.0, 'asymmetry': 0.0}
    
    return adjusted_weights
```

### Proposition 3 : Gestion des Cas Limites avec Impact Non-Lin√©aire

**Principe** : Si une m√©trique est tr√®s mauvaise (< 50%), elle devrait avoir un impact n√©gatif plus important.

**Avantages** :
- D√©tecte mieux les probl√®mes critiques
- √âvite les faux positifs (bon score alors qu'il y a un probl√®me)
- Plus r√©aliste pour le diagnostic

**Impl√©mentation** :

```python
def apply_non_linear_penalty(score: float, threshold: float = 50.0) -> float:
    """
    Applique une p√©nalit√© non-lin√©aire si le score est en dessous du seuil
    """
    if score >= threshold:
        return score
    else:
        # P√©nalit√© quadratique pour les scores faibles
        # Exemple : score 30% ‚Üí p√©nalit√© ‚Üí ~18%
        penalty_factor = (score / threshold) ** 2
        return score * penalty_factor

# Utilisation dans le calcul
sector_score_penalized = apply_non_linear_penalty(sector_score, threshold=90.0)
quality_score_penalized = apply_non_linear_penalty(quality_score, threshold=70.0)
azimuth_final_penalized = apply_non_linear_penalty(azimuth_final, threshold=75.0)
asymmetry_final_penalized = apply_non_linear_penalty(asymmetry_final, threshold=75.0)
```

### Proposition 4 : Normalisation et Validation des Scores

**Principe** : S'assurer que tous les scores sont dans une plage valide et coh√©rente.

**Avantages** :
- √âvite les erreurs de calcul
- Assure la coh√©rence des r√©sultats
- Facilite le d√©bogage

**Impl√©mentation** :

```python
def normalize_score(score: Optional[float], default: float = 0.0, min_val: float = 0.0, max_val: float = 100.0) -> float:
    """
    Normalise un score dans la plage [min_val, max_val]
    """
    if score is None:
        return default
    
    # Clamper dans la plage valide
    score = max(min_val, min(max_val, score))
    
    return score

# Utilisation
sector_score = normalize_score(avg_percentage, default=0.0)
quality_score = normalize_score(quality_score, default=0.0)
azimuth_final = normalize_score(azimuth_score, default=0.0)  # 0 au lieu de 100 si non disponible
asymmetry_final = normalize_score(asymmetry_score, default=0.0)  # 0 au lieu de 100 si non disponible
```

### Proposition 5 : Calcul Final Optimis√© (Combinant toutes les optimisations)

**Impl√©mentation compl√®te** :

```python
# Calcul multi-crit√®res optimis√©
def calculate_optimized_percentage(
    avg_percentage: float,
    consistency: Optional[float],
    stability: Optional[float],
    azimuth_score: Optional[float],
    azimuth_cv: Optional[float],
    asymmetry_score: Optional[float],
    asymmetry_percent: Optional[float],
    num_readings: int
) -> float:
    """
    Calcule le pourcentage d'alignement avec pond√©ration adaptative et gestion des cas limites
    """
    # 1. Normaliser les scores
    sector_score = normalize_score(avg_percentage, default=0.0)
    
    quality_score = 0.0
    if consistency is not None and stability is not None:
        quality_score = normalize_score((consistency + stability) / 2, default=0.0)
    elif consistency is not None:
        quality_score = normalize_score(consistency, default=0.0)
    elif stability is not None:
        quality_score = normalize_score(stability, default=0.0)
    
    azimuth_final = normalize_score(azimuth_score, default=0.0)  # 0 si non disponible
    asymmetry_final = normalize_score(asymmetry_score, default=0.0)  # 0 si non disponible
    
    # 2. Calculer les poids adaptatifs
    weights = calculate_confidence_weights(
        num_readings=num_readings,
        consistency=consistency,
        stability=stability,
        azimuth_cv=azimuth_cv,
        asymmetry_percent=asymmetry_percent
    )
    
    # 3. Appliquer les p√©nalit√©s non-lin√©aires pour les scores faibles
    sector_score_penalized = apply_non_linear_penalty(sector_score, threshold=90.0)
    quality_score_penalized = apply_non_linear_penalty(quality_score, threshold=70.0)
    azimuth_final_penalized = apply_non_linear_penalty(azimuth_final, threshold=75.0)
    asymmetry_final_penalized = apply_non_linear_penalty(asymmetry_final, threshold=75.0)
    
    # 4. Calcul final avec poids adaptatifs
    adjusted_percentage = (
        sector_score_penalized * weights['sector'] +
        quality_score_penalized * weights['quality'] +
        azimuth_final_penalized * weights['azimuth'] +
        asymmetry_final_penalized * weights['asymmetry']
    )
    
    # 5. Clamper le r√©sultat final dans [0, 100]
    adjusted_percentage = max(0.0, min(100.0, adjusted_percentage))
    
    return adjusted_percentage
```

---

## üìä Comparaison : Avant vs Apr√®s

### Sc√©nario 1 : Toutes les m√©triques disponibles

**Avant** :
- Sector: 95%, Quality: 90%, Azimuth: 85%, Asymmetry: 80%
- Calcul: `95*0.40 + 90*0.30 + 85*0.15 + 80*0.15 = 90.25%`

**Apr√®s** (avec optimisations) :
- M√™me calcul si toutes les m√©triques sont fiables
- R√©sultat similaire mais avec validation et normalisation

### Sc√©nario 2 : M√©triques manquantes (peu de lectures)

**Avant** :
- Sector: 95%, Quality: None, Azimuth: None, Asymmetry: None
- Calcul: `95*0.40 + 100*0.30 + 100*0.15 + 100*0.15 = 98%` ‚ùå (Faux positif)

**Apr√®s** (avec optimisations) :
- Sector: 95%, Quality: 0 (non disponible), Azimuth: 0, Asymmetry: 0
- Poids redistribu√©s: Sector: 100%, Quality: 0%, Azimuth: 0%, Asymmetry: 0%
- Calcul: `95*1.0 = 95%` ‚úÖ (Plus r√©aliste)

### Sc√©nario 3 : M√©trique critique tr√®s faible

**Avant** :
- Sector: 30%, Quality: 90%, Azimuth: 85%, Asymmetry: 80%
- Calcul: `30*0.40 + 90*0.30 + 85*0.15 + 80*0.15 = 63.75%` (Peut masquer le probl√®me)

**Apr√®s** (avec optimisations) :
- Sector: 30% ‚Üí p√©nalit√© ‚Üí ~10%
- Calcul: `10*0.40 + 90*0.30 + 85*0.15 + 80*0.15 = 54.25%` ‚úÖ (D√©tecte mieux le probl√®me)

---

## üéØ Recommandations d'Impl√©mentation

### Phase 1 : Corrections Imm√©diates (Priorit√© Haute)

1. **Remplacer les valeurs par d√©faut 100.0 par 0.0** :
   - Si une m√©trique n'est pas disponible, utiliser 0.0 au lieu de 100.0
   - Cela √©vite les faux positifs

2. **Impl√©menter la pond√©ration adaptative** :
   - Redistribuer les poids si des m√©triques sont manquantes
   - Plus r√©aliste que d'utiliser des valeurs par d√©faut

### Phase 2 : Am√©liorations Moyen Terme (Priorit√© Moyenne)

3. **Ajouter les seuils de confiance** :
   - R√©duire le poids des m√©triques calcul√©es avec peu de donn√©es
   - Augmenter le poids des m√©triques fiables

4. **Impl√©menter la normalisation** :
   - S'assurer que tous les scores sont dans [0, 100]
   - Valider les entr√©es

### Phase 3 : Optimisations Avanc√©es (Priorit√© Basse)

5. **Ajouter les p√©nalit√©s non-lin√©aires** :
   - D√©tecter mieux les probl√®mes critiques
   - √âviter les faux positifs

6. **Ajouter des m√©triques de confiance** :
   - Afficher la confiance de chaque m√©trique dans l'interface
   - Aider l'utilisateur √† interpr√©ter les r√©sultats

---

## üìù Code Propos√© pour `alignment_parser.py`

```python
def calculate_optimized_multi_criteria(
    avg_percentage: float,
    consistency: Optional[float],
    stability: Optional[float],
    azimuth_score: Optional[float],
    azimuth_cv: Optional[float],
    asymmetry_score: Optional[float],
    asymmetry_percent: Optional[float],
    num_readings: int
) -> Tuple[float, Dict[str, float]]:
    """
    Calcule le pourcentage d'alignement avec pond√©ration adaptative
    
    Returns:
        (adjusted_percentage, weights_used)
    """
    # Normaliser les scores (0 si non disponible au lieu de 100)
    sector_score = max(0.0, min(100.0, avg_percentage))
    
    quality_score = 0.0
    if consistency is not None and stability is not None:
        quality_score = max(0.0, min(100.0, (consistency + stability) / 2))
    elif consistency is not None:
        quality_score = max(0.0, min(100.0, consistency))
    elif stability is not None:
        quality_score = max(0.0, min(100.0, stability))
    
    azimuth_final = max(0.0, min(100.0, azimuth_score)) if azimuth_score is not None else 0.0
    asymmetry_final = max(0.0, min(100.0, asymmetry_score)) if asymmetry_score is not None else 0.0
    
    # Calculer les poids adaptatifs
    has_quality = quality_score > 0
    has_azimuth = azimuth_final > 0
    has_asymmetry = asymmetry_final > 0
    
    # Poids de base
    base_weights = {
        'sector': 0.40,
        'quality': 0.30 if has_quality else 0.0,
        'azimuth': 0.15 if has_azimuth else 0.0,
        'asymmetry': 0.15 if has_asymmetry else 0.0
    }
    
    # Facteurs de confiance bas√©s sur le nombre de lectures
    confidence_factors = {
        'sector': 1.0,  # Toujours fiable
        'quality': min(1.0, num_readings / 3.0) if has_quality else 0.0,
        'azimuth': min(1.0, num_readings / 3.0) if has_azimuth else 0.0,
        'asymmetry': min(1.0, num_readings / 3.0) if has_asymmetry else 0.0
    }
    
    # Ajuster les poids avec les facteurs de confiance
    adjusted_weights = {
        k: base_weights[k] * confidence_factors[k]
        for k in base_weights
    }
    
    # Normaliser pour que la somme = 1.0
    total_weight = sum(adjusted_weights.values())
    if total_weight > 0:
        adjusted_weights = {k: v / total_weight for k, v in adjusted_weights.items()}
    else:
        # Fallback : utiliser seulement le score de secteurs
        adjusted_weights = {'sector': 1.0, 'quality': 0.0, 'azimuth': 0.0, 'asymmetry': 0.0}
    
    # Appliquer des p√©nalit√©s non-lin√©aires pour les scores tr√®s faibles
    def apply_penalty(score: float, threshold: float = 50.0) -> float:
        if score >= threshold:
            return score
        # P√©nalit√© quadratique pour les scores < threshold
        penalty_factor = (score / threshold) ** 2
        return score * penalty_factor
    
    sector_penalized = apply_penalty(sector_score, threshold=90.0)
    quality_penalized = apply_penalty(quality_score, threshold=70.0) if has_quality else 0.0
    azimuth_penalized = apply_penalty(azimuth_final, threshold=75.0) if has_azimuth else 0.0
    asymmetry_penalized = apply_penalty(asymmetry_final, threshold=75.0) if has_asymmetry else 0.0
    
    # Calcul final
    adjusted_percentage = (
        sector_penalized * adjusted_weights['sector'] +
        quality_penalized * adjusted_weights['quality'] +
        azimuth_penalized * adjusted_weights['azimuth'] +
        asymmetry_penalized * adjusted_weights['asymmetry']
    )
    
    # Clamper dans [0, 100]
    adjusted_percentage = max(0.0, min(100.0, adjusted_percentage))
    
    return adjusted_percentage, adjusted_weights
```

---

## ‚úÖ Conclusion

Les optimisations propos√©es permettront :

1. **√âviter les faux positifs** : Utiliser 0.0 au lieu de 100.0 pour les m√©triques manquantes
2. **Pond√©ration adaptative** : Ajuster les poids selon la disponibilit√© des donn√©es
3. **Seuils de confiance** : R√©duire le poids des m√©triques peu fiables
4. **Gestion des cas limites** : D√©tecter mieux les probl√®mes critiques avec des p√©nalit√©s non-lin√©aires
5. **Normalisation** : Assurer la coh√©rence des r√©sultats

Ces am√©liorations rendront le calcul multi-crit√®res plus fiable et plus r√©aliste, surtout dans les cas o√π certaines m√©triques ne sont pas disponibles ou sont peu fiables.

